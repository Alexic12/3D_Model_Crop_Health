{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bJVCAmp2YcUm"
   },
   "source": [
    "0. Se procede con la instalación de las librerias de trabajo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8735,
     "status": "ok",
     "timestamp": 1741141565357,
     "user": {
      "displayName": "Alejandro Puerta",
      "userId": "00701489479085492105"
     },
     "user_tz": 300
    },
    "id": "4d1-Dnd8PZsg",
    "outputId": "e6385b4f-1a02-4d93-ac0a-33bd2603ffc8"
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1skOtO8YLocB"
   },
   "source": [
    "1. Se cargan las librerias de trabajo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 837,
     "status": "ok",
     "timestamp": 1741141595439,
     "user": {
      "displayName": "Alejandro Puerta",
      "userId": "00701489479085492105"
     },
     "user_tz": 300
    },
    "id": "rwsdMtCqXG8p",
    "outputId": "711b6241-1674-497f-ffef-b65cd8ec90e0"
   },
   "outputs": [],
   "source": [
    "#Se cargan las librerías de trabajo\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from scipy.stats import skew\n",
    "import openpyxl\n",
    "import random\n",
    "\n",
    "#Para cargar los archivos automáticamente del drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "#Se procede con el proceso de clusterización\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "#Se procede con el pronóstico de las variables meteorológicas\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.regularizers import l2,L1,L1L2\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "#Se eliminan los warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eej55v5M6_P9"
   },
   "source": [
    "**Prospectiva Paramétros de Riesgo**\n",
    "\n",
    "1. Se procede con el pronóstico del patrón prospectivo de las variables agroclimáticas\n",
    "*   Modelo neuronal del riesgo\n",
    "*   Aquí se hace el pronóstico de cada una de las variables\n",
    "*  Para el caso de las variables climáticas de entrada se les calcula los paramétros de riesgo mes a mes (solo 12 datos).\n",
    "*  Para el caso de la variable de salida se hace un total de 360 datos (año siguiente)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1741141598182,
     "user": {
      "displayName": "Alejandro Puerta",
      "userId": "00701489479085492105"
     },
     "user_tz": 300
    },
    "id": "1s4bU8LUkdME"
   },
   "outputs": [],
   "source": [
    "def Emision(i2,XDe,NIT,NR):\n",
    "\n",
    "  #i2: Indica la variable climática (parámetro) a analizar.\n",
    "  #XDe: Datos de Entrada - Aquí van solo las variables climáticas\n",
    "  #NIT: Número de Iteraciones\n",
    "  #NR: Número de Retardos Mensuales\n",
    "\n",
    "  #''''''''''''''''''''''''''''''''''''''''''''''\n",
    "  #1. Se procede con la construcción de los Datos\n",
    "  #''''''''''''''''''''''''''''''''''''''''''''''\n",
    "  npr=30 #Número de valores de pronóstico adelante\n",
    "  XDst=np.zeros((len(XDe)-30*(NR-1),NR))\n",
    "  XDen = (XDe - XDe.min()) / (XDe.max() - XDe.min())\n",
    "  XDe2=XDe\n",
    "  XDe=XDen\n",
    "\n",
    "  for k in range(NR):\n",
    "    for i in range(len(XDe)-30*(NR-1)):\n",
    "      XDst[i,k]=XDe[i+k*30,]\n",
    "\n",
    "  Vmax=np.max(XDst[:,0])\n",
    "\n",
    "  #Se procede con la construcción dle vector de salida\n",
    "  ydst=np.zeros((len(XDe)-30*(NR-1)))\n",
    "\n",
    "  for i in range(len(XDe)-(360+30*(NR-1))):\n",
    "    ydst[i]=XDe[i+(360+30*(NR-1)),]\n",
    "\n",
    "  dfst=pd.DataFrame(np.column_stack((XDst,ydst)))\n",
    "\n",
    "  #''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "  #2. Se procede con la configuración del modelo neuronal\n",
    "  #''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "  XDn=XDst[:-360,:]\n",
    "  ydn=ydst[:-360]\n",
    "\n",
    "  drpt=0.01; prl1=0.001\n",
    "\n",
    "  model = Sequential()\n",
    "  model.add(Dense(100, activation='relu', use_bias=False,input_dim=NR,kernel_regularizer=l2(prl1)))\n",
    "  model.add(Dropout(drpt))\n",
    "  model.add(Dense(50, activation='relu', use_bias=False,kernel_regularizer=l2(prl1)))\n",
    "  model.add(Dropout(drpt))\n",
    "  model.add(Dense(25, activation='relu', use_bias=False,kernel_regularizer=l2(prl1)))\n",
    "  model.add(Dropout(drpt))\n",
    "  model.add(Dense(1, activation='relu', use_bias=False,kernel_regularizer=l2(prl1)))\n",
    "  model.compile(optimizer='adam', loss='mse',metrics=['acc'])\n",
    "\n",
    "  early_stopping = EarlyStopping(monitor='loss', patience=10,mode=\"min\",restore_best_weights=True,verbose=1)\n",
    "  history=model.fit(XDn,ydn,epochs=NIT,batch_size=250,callbacks=[early_stopping],verbose=0)\n",
    "  yr=model.predict(XDn)\n",
    "\n",
    "  plt.figure()\n",
    "  plt.plot(ydn,'r',yr,'b')\n",
    "  plt.show()\n",
    "\n",
    "  #'''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "  #3. Se procede con el pronóstico para el próximo año\n",
    "  #'''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "  XDpn=XDst[-360:,:]\n",
    "  yp=model.predict(XDpn)*((XDe2.max()-XDe2.min())+XDe2.min())\n",
    "\n",
    "  #3.1 Se buscan los percentiles para los datos de pronóstico (yp) por percentil\n",
    "  XC1p=np.percentile(yp,[10,20,30,40,50,60,70,80,90,100])\n",
    "\n",
    "  #3.2 Se hace la clasificación del pronóstico (yp) por nivel de riesgo (1,2,3,4,5)\n",
    "  Vp1=np.zeros((12,1));Vp2=np.zeros((12,1))\n",
    "\n",
    "  for i in range(12):\n",
    "    d2=np.sqrt((XC1p-yp[30*(i+1)-1,])**2)\n",
    "    Vp1[i]=(np.where(d2==np.min(d2))[0])[0]\n",
    "\n",
    "    if int(Vp1[i])<5:\n",
    "       Vp2[i]=4-int(Vp1[i])\n",
    "    else:\n",
    "       Vp2[i]=int(Vp1[i])-5\n",
    "\n",
    "  return np.array(Vp1),np.array(Vp2),yp,XC1p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DZjGa1si1O4p"
   },
   "source": [
    "3. Se procede con la construcción de las matrices de emisión y transición del riesgo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1741141600938,
     "user": {
      "displayName": "Alejandro Puerta",
      "userId": "00701489479085492105"
     },
     "user_tz": 300
    },
    "id": "9GwIEKVReD-i"
   },
   "outputs": [],
   "source": [
    "def MatricesTransicion(XD,XD3,n_var,punto):\n",
    "\n",
    "  #Esto permite hacer la prospectiva frente a la variable de salida\n",
    "  #XCr: Matriz de los niveles de riesgo\n",
    "  #XD: Matriz con los datos climático\n",
    "  #n_var: Indica el número de variables climáticas\n",
    "  #n_components: Indica los clusters de agrupación\n",
    "\n",
    "  #'''''''''''''''''''''''''''''''''''''''''''''\n",
    "  #0. Aquí vamos a leer el punto que se necesita\n",
    "  #'''''''''''''''''''''''''''''''''''''''''''''\n",
    "  LDA=[]\n",
    "\n",
    "  for i in range(len(XD3)):\n",
    "      LDA.append(XD3[i,punto,3])\n",
    "\n",
    "  lonp=XD3[0,punto,1]\n",
    "  latp=XD3[0,punto,2]\n",
    "  #''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "  #1. Se procede con la construccción de la matriz de transición del riesgo\n",
    "  #''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "  seed = np.random.randint(0, 1000)  #Generar una semilla aleatoria\n",
    "  LDA=np.array(XD.iloc[:,n_var]); LDA=1-LDA\n",
    "  mkm=KMeans(n_clusters=n_components,random_state=seed)\n",
    "  mkm.fit(LDA.reshape(-1,1))\n",
    "\n",
    "  #Se pro\n",
    "  XC=np.array(sorted(mkm.cluster_centers_,reverse=False)).reshape(1,n_components)\n",
    "  XCr=np.zeros((len(LDA),1))\n",
    "\n",
    "  for i in range(len(XCr)):\n",
    "    d1=np.sqrt((XC-LDA[i,])**2)\n",
    "    XCr[i,]=(np.where(d1==np.min(d1))[1])[0]\n",
    "    XC[0,int(XCr[i,])]=(LDA[i]+XC[0,int(XCr[i,])])/2\n",
    "\n",
    "  MTr=np.zeros((n_components,n_components))\n",
    "\n",
    "  for i in range(len(XCr)-1):\n",
    "    fila=XCr[i]\n",
    "    col=XCr[i+1]\n",
    "    MTr[int(fila),int(col)]=MTr[int(fila),int(col)]+1\n",
    "\n",
    "  MTr_sf=np.sum(MTr,axis=1)\n",
    "\n",
    "  for i in range(n_components):\n",
    "    for j in range(n_components):\n",
    "      MTr[i,j]=MTr[i,j]/MTr_sf[i]\n",
    "\n",
    "  print(\"La matriz de transición del riesgo del riesgo es:\\n\",MTr)\n",
    "  a=MTr\n",
    "\n",
    "  #''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "  #2. Se procede con la construcción de las matrices de emisión\n",
    "  #''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "  WD=np.zeros((len(LDA),n_var))\n",
    "  XC2=np.zeros((2*n_components,n_var))\n",
    "  mkm=KMeans(n_clusters=2*n_components,random_state=seed)\n",
    "\n",
    "  #2.1 Se procede a incrementar la variedad de los datos para la temperatura\n",
    "  for j in range(n_var):\n",
    "    WD[:,j]=np.array(XD.iloc[:,j])\n",
    "\n",
    "    if j==0 or j==1:\n",
    "      for k in range(len(WD)):\n",
    "        WD[k,j]=(0.9+0.2*random.random())*WD[k,j]\n",
    "\n",
    "    mkm.fit(WD[:,j].reshape(-1,1))\n",
    "    XC2[:,j]=np.array(sorted(mkm.cluster_centers_,reverse=False)).reshape(1,2*n_components)\n",
    "\n",
    "  #2.2 Se determinan los niveles de clasificación or variable\n",
    "  XCwd=np.zeros((len(LDA),n_var))\n",
    "\n",
    "  for j in range(n_var):\n",
    "    for i in range(len(LDA)):\n",
    "      d2=np.sqrt((XC2[:,j]-WD[i,j])**2)\n",
    "      XCwd[i,j]=(np.where(d2==np.min(d2))[0])[0]\n",
    "\n",
    "      if int(XCwd[i,j])<5:\n",
    "        XCwd[i,j]=4-XCwd[i,j]\n",
    "      else:\n",
    "        XCwd[i,j]=XCwd[i,j]-5\n",
    "\n",
    "  MTwd=np.zeros((n_var,n_components,n_components))\n",
    "  MTwd_sf=np.zeros((n_var,n_components))\n",
    "\n",
    "  for j in range(n_var):\n",
    "    for i in range(len(XCr)):\n",
    "      fila=XCr[i]\n",
    "      col=XCwd[i,j]\n",
    "      MTwd[j,int(fila),int(col)]+=1\n",
    "\n",
    "    MTwdt=MTwd[j,:,:].reshape(5,5)\n",
    "    MTwd_sf[j,:]=np.sum(MTwdt,axis=1)\n",
    "\n",
    "    for m in range(n_components):\n",
    "      if MTwd_sf[j,m]==0:\n",
    "        MTwd_sf[j,m]=len(LDA)\n",
    "\n",
    "  for j in range(n_var):\n",
    "    for i in range(n_components):\n",
    "      MTwd[j,i,:]=MTwd[j,i,:]/MTwd_sf[j,i]\n",
    "\n",
    "    print(f\"La matriz de emisión para la variable {titulos[j]} es:\\n\",np.round(MTwd[j,:,:],decimals=3))\n",
    "  b=MTwd\n",
    "\n",
    "  return a, b, XCr, lonp, latp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7FGacV12XOi8"
   },
   "source": [
    "4. Se procede con la prospectiva del riesgo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1741141603489,
     "user": {
      "displayName": "Alejandro Puerta",
      "userId": "00701489479085492105"
     },
     "user_tz": 300
    },
    "id": "ZLr5ub_vjut2"
   },
   "outputs": [],
   "source": [
    "def Prospectiva(i1,XD,XCr,V,aTr,bEm,ydmes):\n",
    "\n",
    "  #i1: Indica el punto de análisis para la rejilla\n",
    "  #V: Indica el vector de prospectiva del riesgo\n",
    "  #aTr: Matriz de transición del riesgo\n",
    "  #bEm: Matriz de emisión dle riesgo\n",
    "  #XCr: Es vector de sanidad vegetal para un punto específico\n",
    "\n",
    "  #'''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "  #1. Se determina la estructura porcentual del riesgo\n",
    "  #'''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "  #Se toma la matriz de las pérdidas\n",
    "  LDA=np.array(XD.iloc[:,n_var]); LDA=1-LDA\n",
    "\n",
    "  #Inercia de las categorías del riesgo\n",
    "  nC=np.zeros((n_components,1))\n",
    "  inr=np.zeros((n_components,))\n",
    "\n",
    "  for j in range(n_var):\n",
    "    nC[j]=len(np.where(XCr==j)[0])\n",
    "    nC[j]=nC[j]/len(LDA)\n",
    "    inr[j]=nC[j]\n",
    "\n",
    "  print(\"La estructura porcentual del riesgo es:\\n\",nC)\n",
    "\n",
    "  #'''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "  #2. Patrón de evolución de las variables observables\n",
    "  #'''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "  XLDA=np.zeros((1000,V.shape[1]))\n",
    "  XInf=np.zeros((V.shape[1],12))\n",
    "\n",
    "  #2.1 Estado Actual\n",
    "  LDA = LDA.astype(np.float64)\n",
    "  XInf[0,0]=ydmes[0,0];XInf[0,1]=ydmes[0,1];XInf[0,2]=ydmes[0,2];\n",
    "  XInf[0,3]=ydmes[0,3];XInf[0,4]=ydmes[0,4];\n",
    "  XInf[0,5]=np.round(skew(LDA),decimals=3)\n",
    "  XInf[0,6]=np.round(nC[0]+nC[1],decimals=3)  #Pérdidas Esperadas\n",
    "  XInf[0,7]=np.round(nC[2]+nC[3],decimals=3)  #Pérdidas No Esperadas\n",
    "  XInf[0,8]=np.round(nC[4],decimals=3)\n",
    "  XInf[0,9]=np.round(np.mean(LDA),decimals=3)\n",
    "  XInf[0,10]=np.round(np.percentile(LDA,75),decimals=3)\n",
    "  XInf[0,11]=np.round(np.percentile(LDA,99),decimals=3)\n",
    "\n",
    "  #Patrón cualitativo - Caracterización Variables Observables\n",
    "  VC=[]\n",
    "  for k in range(V.shape[1]):\n",
    "    if V[4,k]==0:\n",
    "      VC.append('High '+str(k+1))\n",
    "    if V[4,k]==1:\n",
    "      VC.append('Average '+str(k+1))\n",
    "    if V[4,k]==2:\n",
    "      VC.append('Low '+str(k+1))\n",
    "    if V[4,k]==3:\n",
    "      VC.append('Very Low '+str(k+1))\n",
    "    if V[4,k]==4:\n",
    "      VC.append('Dry '+str(k+1))\n",
    "\n",
    "  alpha = np.zeros((V.shape[1], aTr.shape[0]))\n",
    "  alpha2 = np.zeros((V.shape[1], aTr.shape[0]))\n",
    "\n",
    "  den=0\n",
    "  for j in range(n_var):\n",
    "    alpha[0, :] =alpha[0, :]+ inr * bEm[j,:, V[j,0]]\n",
    "    den=den+bEm[j,:, V[j,0]]\n",
    "\n",
    "  alpha[0, ]=alpha[0, ]/np.sum(alpha[0, ])\n",
    "\n",
    "  NDm=np.int32(1000*(alpha[0, ]))\n",
    "\n",
    "  m1=-1\n",
    "  for k in range(n_components):\n",
    "      filas=np.where((k==XCr))[0]\n",
    "      LDAm=LDA[filas]\n",
    "      um=np.mean(LDAm)\n",
    "\n",
    "      print(\"Parámetro de Riesgo\",k)\n",
    "      print(\"La media del complemento del parametro de riesgo es:\",um)\n",
    "      print(\"La cantidad de eventos de riesgo por parametro\",len(LDAm))\n",
    "      sigmam=np.sqrt(np.var(LDAm))\n",
    "\n",
    "      for i in range(NDm[k]):\n",
    "        m1=m1+1\n",
    "        XLDA[m1,0]=(0.8+0.4*random.random())*np.random.normal(um,2*sigmam)\n",
    "\n",
    "  alpha2=alpha\n",
    "  XInf[1,0]=ydmes[0,0];XInf[1,1]=ydmes[0,1];XInf[1,2]=ydmes[0,2];\n",
    "  XInf[1,3]=ydmes[0,3];XInf[1,4]=ydmes[0,4];\n",
    "  XInf[1,5]=np.round(skew(XLDA[:,0]),decimals=3)\n",
    "  XInf[1,6]=np.round(alpha2[0,0]+alpha2[0,1],decimals=3)\n",
    "  XInf[1,7]=np.round(alpha2[0,2]+alpha2[0,3],decimals=3)\n",
    "  XInf[1,8]=np.round(alpha2[0,4],decimals=3)\n",
    "  XInf[1,9]=np.round(np.mean(XLDA[:,0]),decimals=3)\n",
    "  XInf[1,10]=np.round(np.percentile(XLDA[:,0],75),decimals=3)\n",
    "  XInf[1,11]=np.round(np.percentile(XLDA[:,0],99),decimals=3)\n",
    "\n",
    "  #''''''''''''''''''''''''''''''''''''''''''''''\n",
    "  #3. Evolución del Riesgo Prospectiva del Riesgo\n",
    "  #''''''''''''''''''''''''''''''''''''''''''''''\n",
    "  for t in range(1,V.shape[1]):\n",
    "    den=0\n",
    "    for j in range(aTr.shape[0]):\n",
    "      for m in range(n_var):\n",
    "        alpha[t, j] =alpha[t, j]+ alpha[t - 1].dot(aTr[:, j]) * bEm[m,j,V[m,t]]\n",
    "        den=den+np.sum(bEm[m,j, V[m,t]]*aTr[:,j])\n",
    "\n",
    "    alpha[t, ]=alpha[t, ]/np.sum(alpha[t, ])\n",
    "\n",
    "    NDm=np.int32(1000*(alpha[t, ]))\n",
    "\n",
    "    m1=-1\n",
    "    for k in range(n_components):\n",
    "\n",
    "      filas=np.where((k==XCr))[0]\n",
    "      LDAm=LDA[filas]\n",
    "      um=np.mean(LDAm)\n",
    "      sigmam=np.sqrt(np.var(LDAm))\n",
    "\n",
    "      for i in range(NDm[k]):\n",
    "        m1=m1+1\n",
    "        XLDA[m1,t]=(0.9+0.2*random.random())*np.random.normal(um,sigmam)\n",
    "\n",
    "    alpha2=alpha\n",
    "    XInf[t,0]=ydmes[t,0];XInf[t,1]=ydmes[t,1];XInf[t,2]=ydmes[t,2];\n",
    "    XInf[t,3]=ydmes[t,3];XInf[t,4]=ydmes[t,4];\n",
    "    XInf[t,5]=np.round(skew(XLDA[:,t-1]),decimals=3)\n",
    "    XInf[t,6]=np.round(alpha2[t,0]+alpha2[t,1],decimals=3)\n",
    "    XInf[t,7]=np.round(alpha2[t,2]+alpha2[t,3],decimals=3);\n",
    "    XInf[t,8]=np.round(alpha2[t,4],decimals=3)\n",
    "    XInf[t,9]=np.round(np.mean(XLDA[:,t-1]),decimals=3)\n",
    "    XInf[t,10]=np.round(np.percentile(XLDA[:,t-1],75),decimals=3)\n",
    "    XInf[t,11]=np.round(np.percentile(XLDA[:,t-1],99),decimals=3)\n",
    "\n",
    "  VC=np.array(VC)\n",
    "\n",
    "  return VC,XInf,XLDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "63DpTEh6-j__"
   },
   "source": [
    "#**Evolución Espacial del Riesgo**\n",
    "0. Se procede con la organización del archivo del clima\n",
    "* Este procedimiento permite la organización temporal del archivo climático."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5292,
     "status": "ok",
     "timestamp": 1741141673963,
     "user": {
      "displayName": "Alejandro Puerta",
      "userId": "00701489479085492105"
     },
     "user_tz": 300
    },
    "id": "FluCkYv7-n4j",
    "outputId": "ea105b48-78bc-459e-be65-f8aecd93ed84"
   },
   "outputs": [],
   "source": [
    "#1. Se procede con la selección de la carpeta de trabajo\n",
    "indice=input(\"Ingresar el nombre del indice de vegetación:\")\n",
    "año=input(\"Ingresar el año de análisis:\")\n",
    "\n",
    "nxl='/content/drive/MyDrive/Software-EAFIT-DMU/Software_Puerta/'+indice+'_'+año+'/Clima_'+indice+'_'+año+'.xlsx'\n",
    "print(nxl)\n",
    "\n",
    "#2. Se procede con la lectura de los datos climáticos\n",
    "dfc = pd.read_excel(nxl, sheet_name=0)\n",
    "\n",
    "#2.1 Invertir el orden de las filas\n",
    "df_invertido = dfc.iloc[::-1]\n",
    "\n",
    "ruta_salida = 'Clima_'+indice+'_'+año+'_O.xlsx'  # Cambia esto por la ruta de salida\n",
    "nxl2='/content/drive/MyDrive/Software-EAFIT-DMU/Software_Puerta/'+indice+'_'+año+'/'+ruta_salida\n",
    "df_invertido.to_excel(nxl2, index=False, sheet_name='Sheet 1')\n",
    "\n",
    "print(f\"El archivo con las filas invertidas se guardó en: {nxl2}\")\n",
    "df_invertido.to_excel(ruta_salida, index=False, sheet_name='Sheet 1')\n",
    "\n",
    "print(f\"El archivo con las filas invertidas se guardó en: {ruta_salida}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Tmv3_cMKXhH"
   },
   "source": [
    "1. Se procede con la construcción del patrón prospectivo para las variables agroclimáticas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4956,
     "status": "ok",
     "timestamp": 1741141702319,
     "user": {
      "displayName": "Alejandro Puerta",
      "userId": "00701489479085492105"
     },
     "user_tz": 300
    },
    "id": "iiXd22fDYm_4",
    "outputId": "a1052589-8b6c-4609-a02c-cc5c42d563dc"
   },
   "outputs": [],
   "source": [
    "#1. Se procede con la selección del archivo de trabajo\n",
    "indice=input(\"Ingresar el nombre del indice de vegetación: \")\n",
    "año=input(\"Ingresar el año de análisis: \")\n",
    "\n",
    "nxl='/content/drive/MyDrive/Software-EAFIT-DMU/Software_Puerta/'+indice+'_'+año+'/'+'Clima_'+indice+'_'+año+'_O.xlsx'\n",
    "ruta_destino=nxl\n",
    "\n",
    "XDB = pd.read_excel(nxl, sheet_name=0)\n",
    "XDB2 = pd.read_excel(nxl, sheet_name=0)\n",
    "XDB = XDB.dropna()\n",
    "\n",
    "#2. Se determinan las filas que poseen datos\n",
    "XDB=XDB[XDB['Fuente de datos']!='-']\n",
    "columnas_interes=[7,8,11,12,13,4]\n",
    "XD = XDB.iloc[:, columnas_interes]\n",
    "XD2 = XDB2.iloc[:, columnas_interes]\n",
    "titulos=['Máx grado C','Mín grado C','Viento (m/s)','Humedad (%)','Precipitaciones (mm)']\n",
    "\n",
    "#3. Se crea el informe de salida solo con las fechas en las cuales se tomaron las imagenes satelitales\n",
    "impath2='/content/drive/MyDrive/Software-EAFIT-DMU/Software_Puerta/'+indice+'_'+año+'/'\n",
    "XDB.to_excel(impath2+\"Clima_\"+indice+\"_\"+año+\"_HMM\"+\".xlsx\")\n",
    "\n",
    "#4. Parámetros de configuración\n",
    "n_components=5  #Niveles de clasificación del riesgo\n",
    "n_var=5         #Variables agroclimáticas de entrada\n",
    "print(\"El número de parametros de riesgo es:\",n_components)\n",
    "print(\"El número de variables agroclimáticas es:\",n_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jb21xWaG-32g"
   },
   "source": [
    "3. Se crea el patrón de evolución para el año siguiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 73597,
     "status": "ok",
     "timestamp": 1741141882961,
     "user": {
      "displayName": "Alejandro Puerta",
      "userId": "00701489479085492105"
     },
     "user_tz": 300
    },
    "id": "g0Axvt0aKdxL",
    "outputId": "15b3a739-3f15-4fdf-956f-68d6c3b2a30d"
   },
   "outputs": [],
   "source": [
    "#1. Se configuran los valores de referencia para cada variable (de deciles a quintiles)\n",
    "Vref=np.array([0,1,2,3,4,5,6,7,8,9])\n",
    "XCpar = np.zeros((5, 10))\n",
    "Vnref=np.array([4,3,2,1,0,0,1,2,3,4])\n",
    "\n",
    "#2. Se crean los niveles climáticos para la evolución prospectiva del riesgo\n",
    "V = np.random.randint(0, 5, size=(n_var, 12))\n",
    "Vn = np.random.randint(0, 5, size=(n_var, 12))\n",
    "mes=np.array([1,2,3,4,5,6,7,8,9,10,11,12])\n",
    "\n",
    "#3. Se presenta la construcción de los patrones climáticos\n",
    "ydpar=np.zeros((360,n_var))\n",
    "\n",
    "for i in range(n_var):\n",
    "  XDe=np.array(XD2.iloc[:,i])\n",
    "  NNEm=(Emision(i,XDe,500,4))\n",
    "  print(f\"La Evolución de la Variable {titulos[i]} es:\")\n",
    "  print(\"Los niveles  del riesgo son:\")\n",
    "  print(Vref)\n",
    "  print(f\"Los cluster de referencia para la Variable {titulos[i]} son:\")\n",
    "  XCpar[i,:]=NNEm[3]\n",
    "  print(XCpar[i,:])\n",
    "  print(\"Los niveles absolutos del riesgo son:\")\n",
    "  Vn[i,:]=NNEm[0].reshape(1,12)\n",
    "  print(Vn[i,:])\n",
    "  print(\"Los niveles relativos del riesgo son:\")\n",
    "  V[i,:]=NNEm[1].reshape(1,12)\n",
    "  print(V[i,:])\n",
    "\n",
    "  #4. Se procede con el pronóstico de\n",
    "  ydpar[:,i]=NNEm[2].reshape(360,)\n",
    "  #print(ydpar[:,i])\n",
    "\n",
    "#5. Se procde con al configuraciónde los informes del riesgo\n",
    "dfpar=pd.DataFrame(np.column_stack((Vref,Vnref,XCpar.transpose())))\n",
    "dfpar.columns=['Niveles','Parametros','Max C','Min  C','Viento (m/s)','Humedad (%)','Precip. (mm)']\n",
    "dfpar.head(10)\n",
    "\n",
    "#Se procede con la presentación de los datos de pronóstico mes a mes\n",
    "ydmes=np.zeros((12,5))\n",
    "\n",
    "for i in range(12):\n",
    "  ydmes[i,:]=ydpar[30*(i)-1,:]\n",
    "  print(ydmes[i,:])\n",
    "\n",
    "dfevol=pd.DataFrame(np.column_stack((mes,ydmes)))\n",
    "dfevol.columns=['Mes'+str(int(año)+1),'Max C','Min  C','Viento (m/s)','Humedad (%)','Precip. (mm)']\n",
    "dfevol.head(10)\n",
    "\n",
    "#Se crea el archivo con la prospectiva\n",
    "ruta_excel = '/content/drive/MyDrive/Software-EAFIT-DMU/Software_Puerta/'+indice+'_'+año+'/Prospective_'+indice+'_'+str(int(año)+1)+'.xlsx'\n",
    "\n",
    "with pd.ExcelWriter(ruta_excel, engine='openpyxl') as writer:\n",
    "    dfpar.to_excel(writer, index=False, sheet_name=str('Clusters'))\n",
    "\n",
    "# Ruta del archivo Excel\n",
    "ruta_excel = '/content/drive/MyDrive/Software-EAFIT-DMU/Software_Puerta/'+indice+'_'+año+'/Prospective_'+indice+'_'+str(int(año)+1)+'.xlsx'\n",
    "\n",
    "with pd.ExcelWriter(ruta_excel, mode='a', engine='openpyxl') as writer:\n",
    "   dfevol.to_excel(writer, index=False, sheet_name=str('Prospectiva'+str(int(año)+1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lv9yHcutLac6"
   },
   "source": [
    "2. Se procede con la selección de cada uno de los puntos espaciales para el análisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 152494,
     "status": "ok",
     "timestamp": 1741142976013,
     "user": {
      "displayName": "Alejandro Puerta",
      "userId": "00701489479085492105"
     },
     "user_tz": 300
    },
    "id": "thQFhl081J2v",
    "outputId": "720ddfa0-1d56-439a-bea8-2c674e75f769"
   },
   "outputs": [],
   "source": [
    "#Se procede con la carga de la información\n",
    "res=5 #Resolución de la rejilla de trabajo\n",
    "nxl3='/content/drive/MyDrive/Software-EAFIT-DMU/Software_Puerta/'+indice+'_'+año+'/Informe '+indice+' QGIS '+año+'.xlsx'\n",
    "libro = openpyxl.load_workbook(nxl3)\n",
    "hojas = libro.sheetnames\n",
    "\n",
    "XDB3 = pd.read_excel(nxl3, sheet_name=None)\n",
    "array_hojas = list(XDB3.values())\n",
    "XD3=np.empty((len(XDB3),5*5,5))\n",
    "\n",
    "for i, hoja in enumerate(array_hojas):\n",
    "      XD3[i,:,:]=hoja\n",
    "\n",
    "#Es importante determinar la resolución espacial de análisis\n",
    "res=5\n",
    "MTr2=np.zeros((res**2,n_components,n_components))  #Matriz transición del riesgo\n",
    "MTwd2=np.zeros((res**2,n_var,n_components,n_components)) #Matrices de Emisión\n",
    "\n",
    "#Se procede con el ingreso de la pérdida por hectarea por cultivo\n",
    "PRef=np.float128(input(\"Ingresar productividad de referencia (USD/Ha):\"))\n",
    "Ef=0.70\n",
    "PRef=PRef*(1-Ef)\n",
    "\n",
    "for i1 in range(res*res):\n",
    "  print(i1)\n",
    "\n",
    "  #Se crea el vector de riesgo\n",
    "  punto=i1\n",
    "\n",
    "  #Se procede con la obtención de las matrices de Transición y Emisión\n",
    "  MTrr=MatricesTransicion(XD,XD3,n_var,punto)\n",
    "  MTr2[i1,:,:]=MTrr[0]\n",
    "  MTwd2[i1,:,:,:]=MTrr[1]\n",
    "  XCr=MTrr[2]\n",
    "  lonp=XD3[0,i1,1];latp=XD3[0,i1,2]\n",
    "\n",
    "  #Se procede a mostrar la información de la zona de estudio\n",
    "  infm=[i1,lonp,latp]\n",
    "  dfm2=pd.DataFrame(np.column_stack((infm)))\n",
    "  dfm2.columns=['Punto','Longitud','Latitud']\n",
    "  display(dfm2)\n",
    "\n",
    "  #Se procede con la impresión de las matrices de riesgo\n",
    "  print(f\"La matriz de transición del riesgo del punto {i1} es:\\n\",MTrr[0])\n",
    "\n",
    "  for j1 in range(n_var):\n",
    "    print(f\"La matriz de emisión para la variable {titulos[j1]} es:\\n\",np.round(MTwd2[i1,j1,:,:],decimals=3))\n",
    "\n",
    "  #Se procede con la evolución prospectiva del riesgo\n",
    "  aTr=MTr2[i1,:,:];bEm=MTwd2[i1,:,:,:]; NDVI=np.zeros((12,1))\n",
    "\n",
    "  dfpr=Prospectiva(i1,XD,XCr,V,aTr,bEm,ydmes)\n",
    "  VC=dfpr[0]\n",
    "  XInf2=dfpr[1]\n",
    "  XLDA=dfpr[2]\n",
    "\n",
    "  #''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "  #4. Distribuciones de Pérdidas - Periodo Prospectiva (12 Meses)\n",
    "  #''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "  plt.figure()\n",
    "\n",
    "  for k in range(1,V.shape[1]):\n",
    "      XLDA[:,k]=XLDA[:,k]*PRef\n",
    "      sns.kdeplot(XLDA[:,k], shade=True,bw=0.5)\n",
    "\n",
    "  #Se procede con la gráfica de la distribución de pérdidas\n",
    "  plt.legend(labels=VC[-10:,])\n",
    "  plt.title('Monthly Risk Evolution Punto '+str(i1))\n",
    "  plt.xlabel('Losses (USD/Month-Zone)')\n",
    "  plt.ylabel('Density')\n",
    "  plt.grid(True)\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "  #Para la configuración del informe\n",
    "  NDVI=XInf2[:,11].copy()\n",
    "  MPerd=XInf2[:,9:12]\n",
    "\n",
    "  for i2 in range(len(MPerd)):\n",
    "    for j2 in range(MPerd.shape[1]):\n",
    "      MPerd[i2,j2]=PRef/np.abs(1-MPerd[i2,j2])\n",
    "\n",
    "  dfm=pd.DataFrame(np.column_stack((VC,XInf2[:,0:5],NDVI,XInf2[:,5],XInf2[:,6:9],MPerd[:,:])))\n",
    "  dfm.columns=['WD','Max C','Min  C','Viento (m/s)','Humedad (%)','Precip. (mm)',str(indice),'Skewness','%C1','%C2','%C3','Mean (USD)','75% (USD)','OpVar-99.9% (USD)']\n",
    "  dfm['Max C']=dfm['Max C'].astype(float).map('{:.3f}'.format)\n",
    "  dfm['Min  C']=dfm['Min  C'].astype(float).map('{:.3f}'.format)\n",
    "  dfm['Viento (m/s)']=dfm['Viento (m/s)'].astype(float).map('{:.3f}'.format)\n",
    "  dfm['Humedad (%)']=dfm['Humedad (%)'].astype(float).map('{:.3f}'.format)\n",
    "  dfm['Precip. (mm)']=dfm['Precip. (mm)'].astype(float).map('{:.3f}'.format)\n",
    "  dfm['Skewness']=dfm['Skewness'].astype(float).map('{:.4f}'.format)\n",
    "  dfm[str(indice)]=dfm[str(indice)].astype(float).map('{:.4f}'.format)\n",
    "  dfm['%C1']=dfm['%C1'].astype(float).map('{:.3f}'.format)\n",
    "  dfm['%C2']=dfm['%C2'].astype(float).map('{:.3f}'.format)\n",
    "  dfm['%C3']=dfm['%C3'].astype(float).map('{:.3f}'.format)\n",
    "  dfm['Mean (USD)']=dfm['Mean (USD)'].astype(float).map('{:.2f}'.format)\n",
    "  dfm['75% (USD)']=dfm['75% (USD)'].astype(float).map('{:.2f}'.format)\n",
    "  dfm['OpVar-99.9% (USD)']=dfm['OpVar-99.9% (USD)'].astype(float).map('{:.2f}'.format)\n",
    "\n",
    "  display(dfm)\n",
    "\n",
    "  # Se almacenan los informes de evolución del riesgo\n",
    "  ruta_excel = '/content/drive/MyDrive/Software-EAFIT-DMU/Software_Puerta/'+indice+'_'+año+'/Prospective_'+indice+'_'+str(int(año)+1)+'.xlsx'\n",
    "\n",
    "  with pd.ExcelWriter(ruta_excel, mode='a', engine='openpyxl',if_sheet_exists=\"replace\") as writer:\n",
    "          dfm.to_excel(writer, index=False, sheet_name=str('Point_'+str(i1)))\n",
    "\n",
    "  #Se procede con el almacenamiento de las distribuciones de pérdidas\n",
    "  ruta_excel_2 = '/content/drive/MyDrive/Software-EAFIT-DMU/Software_Puerta/'+indice+'_'+año+'/Prospective_LDA_'+indice+'_'+str(int(año)+1)+'.xlsx'\n",
    "  titulos_LDA=[]\n",
    "\n",
    "  if i1==0:\n",
    "\n",
    "    titulos_LDA=[]\n",
    "\n",
    "    for i2 in range(12):\n",
    "      titulos_LDA.append('Mes' + str(i2))\n",
    "\n",
    "    titulos_LDA2=titulos_LDA\n",
    "    dfXLDA=pd.DataFrame(XLDA)\n",
    "    dfXLDA.columns=titulos_LDA\n",
    "\n",
    "    with pd.ExcelWriter(ruta_excel_2, engine='openpyxl') as writer:\n",
    "      dfXLDA.to_excel(writer, index=False, sheet_name=str('LDA Point_'+str(int(i1))))\n",
    "\n",
    "  else:\n",
    "\n",
    "    dfXLDA=pd.DataFrame(XLDA)\n",
    "    dfXLDA.columns=titulos_LDA2\n",
    "\n",
    "    with pd.ExcelWriter(ruta_excel_2, mode='a', engine='openpyxl') as writer:\n",
    "      dfXLDA.to_excel(writer, index=False, sheet_name=str('LDA Point_'+str(int(i1))))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
